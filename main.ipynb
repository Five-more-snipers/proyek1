{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "45d5c57e-764c-4c81-b0ce-b1cd877338d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:34:38.899649: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-08 14:34:39.070509: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-08 14:34:38.830995: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-08 14:34:38.831566: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-08 14:34:38.958682: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-08 14:34:39.276611: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-08 14:34:39.281877: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-08 14:34:51.250935: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# NOTEBOOK UTAMA UNTUK MENJALANKAN PIPELINE MODULAR\n",
    "# ===============================================================\n",
    "\n",
    "# 1. Impor semua library yang dibutuhkan\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tfx.orchestration.experimental.interactive.interactive_context import InteractiveContext\n",
    "from tfx.components import CsvExampleGen, StatisticsGen, SchemaGen, ExampleValidator, Transform, Tuner, Trainer, Evaluator, Pusher\n",
    "from tfx.proto import trainer_pb2, pusher_pb2, example_gen_pb2\n",
    "from tfx.dsl.components.common.resolver import Resolver\n",
    "from tfx.dsl.input_resolution.strategies.latest_blessed_model_strategy import LatestBlessedModelStrategy\n",
    "from tfx.types import Channel\n",
    "from tfx.types.standard_artifacts import Model, ModelBlessing\n",
    "import tensorflow_model_analysis as tfma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06fa3adb-e259-4ad8-8995-ae1a13a5eb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Konfigurasi Path dan Variabel\n",
    "# --- GANTI DENGAN USERNAME ANDA ---\n",
    "USERNAME = \"raffihakim\"\n",
    "# -----------------------------------\n",
    "\n",
    "# Nama pipeline baru untuk memastikan tidak ada cache lama\n",
    "PIPELINE_NAME = \"student-habits-modular-pipeline\"\n",
    "PIPELINE_ROOT = os.path.join(f'{USERNAME}-pipeline')\n",
    "DATA_ROOT = \"data\"\n",
    "SERVING_MODEL_DIR = os.path.join(PIPELINE_ROOT, \"serving_model\", PIPELINE_NAME)\n",
    "\n",
    "# --- Path ke file-file logika Anda ---\n",
    "TRANSFORM_MODULE_FILE = os.path.join(\"pipeline\", \"student_transform.py\")\n",
    "TUNER_MODULE_FILE = os.path.join(\"pipeline\", \"student_tuner.py\")\n",
    "TRAINER_MODULE_FILE = os.path.join(\"pipeline\", \"student_trainer.py\")\n",
    "# ------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ec50697-dd0b-4cd0-9833-90a8e79f8050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:InteractiveContext metadata_connection_config not provided: using SQLite ML Metadata database at raffihakim-pipeline/metadata.sqlite.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Konteks TFX baru untuk 'student-habits-modular-pipeline' berhasil diinisialisasi.\n"
     ]
    }
   ],
   "source": [
    "# 4. Inisialisasi Ulang InteractiveContext\n",
    "context = InteractiveContext(pipeline_root=PIPELINE_ROOT)\n",
    "print(f\"âœ… Konteks TFX baru untuk '{PIPELINE_NAME}' berhasil diinisialisasi.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5352b26-5264-4779-a12b-c3b7813b6a63",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:apache_beam.runners.interactive.interactive_environment:Dependencies required for Interactive Beam PCollection visualization are not available, please use: `pip install apache-beam[interactive]` to install necessary dependencies to enable all data visualization features.\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "        if (typeof window.interactive_beam_jquery == 'undefined') {\n",
       "          var jqueryScript = document.createElement('script');\n",
       "          jqueryScript.src = 'https://code.jquery.com/jquery-3.4.1.slim.min.js';\n",
       "          jqueryScript.type = 'text/javascript';\n",
       "          jqueryScript.onload = function() {\n",
       "            var datatableScript = document.createElement('script');\n",
       "            datatableScript.src = 'https://cdn.datatables.net/1.10.20/js/jquery.dataTables.min.js';\n",
       "            datatableScript.type = 'text/javascript';\n",
       "            datatableScript.onload = function() {\n",
       "              window.interactive_beam_jquery = jQuery.noConflict(true);\n",
       "              window.interactive_beam_jquery(document).ready(function($){\n",
       "                \n",
       "              });\n",
       "            }\n",
       "            document.head.appendChild(datatableScript);\n",
       "          };\n",
       "          document.head.appendChild(jqueryScript);\n",
       "        } else {\n",
       "          window.interactive_beam_jquery(document).ready(function($){\n",
       "            \n",
       "          });\n",
       "        }"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 1/9 ExampleGen Selesai\n"
     ]
    }
   ],
   "source": [
    "# ===============================================================\n",
    "# 5. Jalankan Komponen Pipeline Secara Berurutan\n",
    "# ===============================================================\n",
    "\n",
    "# --- Jalankan setiap blok kode berikut dalam sel terpisah ---\n",
    "\n",
    "# 1. ExampleGen\n",
    "output_config = example_gen_pb2.Output(split_config=example_gen_pb2.SplitConfig(splits=[\n",
    "    example_gen_pb2.SplitConfig.Split(name=\"train\", hash_buckets=8),\n",
    "    example_gen_pb2.SplitConfig.Split(name=\"eval\", hash_buckets=2)\n",
    "]))\n",
    "example_gen = CsvExampleGen(input_base=DATA_ROOT, output_config=output_config)\n",
    "context.run(example_gen)\n",
    "print(\"âœ… 1/9 ExampleGen Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "47b9dfd0-8ff4-4f4f-a69d-39a569a6e497",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 2/9 StatisticsGen Selesai\n"
     ]
    }
   ],
   "source": [
    "# 2. StatisticsGen\n",
    "statistics_gen = StatisticsGen(examples=example_gen.outputs['examples'])\n",
    "context.run(statistics_gen)\n",
    "print(\"âœ… 2/9 StatisticsGen Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "584a600e-f55c-4bfb-b5f1-ad280fd7e4be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 3/9 SchemaGen Selesai\n"
     ]
    }
   ],
   "source": [
    "# 3. SchemaGen\n",
    "schema_gen = SchemaGen(statistics=statistics_gen.outputs['statistics'])\n",
    "context.run(schema_gen)\n",
    "print(\"âœ… 3/9 SchemaGen Selesai\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3e8afbf5-8a08-4683-bd19-a714e06e649c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 4/9 ExampleValidator Selesai\n"
     ]
    }
   ],
   "source": [
    "# 4. ExampleValidator\n",
    "example_validator = ExampleValidator(statistics=statistics_gen.outputs['statistics'], schema=schema_gen.outputs['schema'])\n",
    "context.run(example_validator)\n",
    "print(\"âœ… 4/9 ExampleValidator Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e58d348-f235-48d2-857b-7ad3c81d5a4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying module.py -> build/lib\n",
      "copying student_trainer.py -> build/lib\n",
      "copying student_transform.py -> build/lib\n",
      "copying student_tuner.py -> build/lib\n",
      "installing to /tmp/tmps7l3tgqr\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/student_transform.py -> /tmp/tmps7l3tgqr\n",
      "copying build/lib/module.py -> /tmp/tmps7l3tgqr\n",
      "copying build/lib/student_trainer.py -> /tmp/tmps7l3tgqr\n",
      "copying build/lib/student_tuner.py -> /tmp/tmps7l3tgqr\n",
      "running install_egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/proyek1/mlops/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running egg_info\n",
      "creating tfx_user_code_Transform.egg-info\n",
      "writing tfx_user_code_Transform.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Transform.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Transform.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Transform.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Transform.egg-info to /tmp/tmps7l3tgqr/tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmps7l3tgqr/tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/WHEEL\n",
      "creating '/tmp/tmp8wvpr843/tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d-py3-none-any.whl' and adding '/tmp/tmps7l3tgqr' to it\n",
      "adding 'module.py'\n",
      "adding 'student_trainer.py'\n",
      "adding 'student_transform.py'\n",
      "adding 'student_tuner.py'\n",
      "adding 'tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/RECORD'\n",
      "removing /tmp/tmps7l3tgqr\n",
      "Processing ./raffihakim-pipeline/_wheels/tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d\n",
      "Processing ./raffihakim-pipeline/_wheels/tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d\n",
      "Processing ./raffihakim-pipeline/_wheels/tfx_user_code_Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Transform\n",
      "Successfully installed tfx-user-code-Transform-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:36:46.519629: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-08 14:36:46.521921: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: raffihakim-pipeline/Transform/transform_graph/5/.temp_path/tftransform_tmp/caeb889c88b442c189d027d76060f342/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: raffihakim-pipeline/Transform/transform_graph/5/.temp_path/tftransform_tmp/caeb889c88b442c189d027d76060f342/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:struct2tensor is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_decision_forests is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:tensorflow_text is not available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 5/9 Transform Selesai\n"
     ]
    }
   ],
   "source": [
    "# 5. Transform\n",
    "transform = Transform(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    module_file=TRANSFORM_MODULE_FILE\n",
    ")\n",
    "context.run(transform)\n",
    "print(\"âœ… 5/9 Transform Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6428ba64-fe1f-425b-b519-4cc7373baf8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 10 Complete [00h 00m 04s]\n",
      "val_root_mean_squared_error: 7.156743049621582\n",
      "\n",
      "Best val_root_mean_squared_error So Far: 4.656599044799805\n",
      "Total elapsed time: 00h 00m 43s\n",
      "Results summary\n",
      "Results in raffihakim-pipeline/.temp/6/student_performance_tuning\n",
      "Showing 10 best trials\n",
      "Objective(name=\"val_root_mean_squared_error\", direction=\"min\")\n",
      "\n",
      "Trial 02 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 160\n",
      "dropout: 0.2\n",
      "learning_rate: 0.01\n",
      "units_1: 192\n",
      "units_2: 192\n",
      "Score: 4.656599044799805\n",
      "\n",
      "Trial 06 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 64\n",
      "dropout: 0.5\n",
      "learning_rate: 0.001\n",
      "units_1: 224\n",
      "units_2: 128\n",
      "Score: 4.7443060874938965\n",
      "\n",
      "Trial 03 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 192\n",
      "dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "units_1: 192\n",
      "units_2: 192\n",
      "Score: 4.843631267547607\n",
      "\n",
      "Trial 07 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 32\n",
      "dropout: 0.1\n",
      "learning_rate: 0.01\n",
      "units_1: 224\n",
      "units_2: 256\n",
      "Score: 4.921535968780518\n",
      "\n",
      "Trial 04 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 256\n",
      "dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "units_1: 192\n",
      "units_2: 192\n",
      "Score: 6.682391166687012\n",
      "\n",
      "Trial 05 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 160\n",
      "dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "units_1: 64\n",
      "units_2: 64\n",
      "Score: 6.98913049697876\n",
      "\n",
      "Trial 09 summary\n",
      "Hyperparameters:\n",
      "num_layers: 1\n",
      "units_0: 160\n",
      "dropout: 0.4\n",
      "learning_rate: 0.001\n",
      "units_1: 128\n",
      "units_2: 192\n",
      "Score: 7.156743049621582\n",
      "\n",
      "Trial 08 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 128\n",
      "dropout: 0.5\n",
      "learning_rate: 0.0001\n",
      "units_1: 224\n",
      "units_2: 160\n",
      "Score: 14.065457344055176\n",
      "\n",
      "Trial 00 summary\n",
      "Hyperparameters:\n",
      "num_layers: 2\n",
      "units_0: 192\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "units_1: 32\n",
      "Score: 17.19774627685547\n",
      "\n",
      "Trial 01 summary\n",
      "Hyperparameters:\n",
      "num_layers: 3\n",
      "units_0: 32\n",
      "dropout: 0.30000000000000004\n",
      "learning_rate: 0.0001\n",
      "units_1: 192\n",
      "units_2: 32\n",
      "Score: 18.362016677856445\n",
      "âœ… 6/9 Tuner Selesai\n"
     ]
    }
   ],
   "source": [
    "# 6. Tuner\n",
    "tuner = Tuner(\n",
    "    module_file=TUNER_MODULE_FILE,\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=1000),\n",
    "    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=500)\n",
    ")\n",
    "context.run(tuner)\n",
    "print(\"âœ… 6/9 Tuner Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1daf8b93-e5f7-44dd-8701-a8c93fcf0dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build\n",
      "creating build/lib\n",
      "copying module.py -> build/lib\n",
      "copying student_trainer.py -> build/lib\n",
      "copying student_transform.py -> build/lib\n",
      "copying student_tuner.py -> build/lib\n",
      "installing to /tmp/tmp4dkeu81z\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/student_transform.py -> /tmp/tmp4dkeu81z\n",
      "copying build/lib/module.py -> /tmp/tmp4dkeu81z\n",
      "copying build/lib/student_trainer.py -> /tmp/tmp4dkeu81z\n",
      "copying build/lib/student_tuner.py -> /tmp/tmp4dkeu81z\n",
      "running install_egg_info\n",
      "running egg_info\n",
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /tmp/tmp4dkeu81z/tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.egg-info\n",
      "running install_scripts\n",
      "creating /tmp/tmp4dkeu81z/tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/WHEEL\n",
      "creating '/tmp/tmpl1fq_eqw/tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d-py3-none-any.whl' and adding '/tmp/tmp4dkeu81z' to it\n",
      "adding 'module.py'\n",
      "adding 'student_trainer.py'\n",
      "adding 'student_transform.py'\n",
      "adding 'student_tuner.py'\n",
      "adding 'tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/METADATA'\n",
      "adding 'tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d.dist-info/RECORD'\n",
      "removing /tmp/tmp4dkeu81z\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/d/proyek1/mlops/lib/python3.10/site-packages/setuptools/command/install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "  warnings.warn(\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n",
      "WARNING:absl:Examples artifact does not have payload_format custom property. Falling back to FORMAT_TF_EXAMPLE\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing ./raffihakim-pipeline/_wheels/tfx_user_code_Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d-py3-none-any.whl\n",
      "Installing collected packages: tfx-user-code-Trainer\n",
      "Successfully installed tfx-user-code-Trainer-0.0+001467eb49da7fd68fe1c87501132413029ed8032fb55aaf26e418633ecfce9d\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " age_xf (InputLayer)         [(None, 1)]                  0         []                            \n",
      "                                                                                                  \n",
      " study_hours_per_day_xf (In  [(None, 1)]                  0         []                            \n",
      " putLayer)                                                                                        \n",
      "                                                                                                  \n",
      " social_media_hours_xf (Inp  [(None, 1)]                  0         []                            \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " netflix_hours_xf (InputLay  [(None, 1)]                  0         []                            \n",
      " er)                                                                                              \n",
      "                                                                                                  \n",
      " attendance_percentage_xf (  [(None, 1)]                  0         []                            \n",
      " InputLayer)                                                                                      \n",
      "                                                                                                  \n",
      " sleep_hours_xf (InputLayer  [(None, 1)]                  0         []                            \n",
      " )                                                                                                \n",
      "                                                                                                  \n",
      " mental_health_rating_xf (I  [(None, 1)]                  0         []                            \n",
      " nputLayer)                                                                                       \n",
      "                                                                                                  \n",
      " exercise_frequency_xf (Inp  [(None, 1)]                  0         []                            \n",
      " utLayer)                                                                                         \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate  (None, 8)                    0         ['age_xf[0][0]',              \n",
      " )                                                                   'study_hours_per_day_xf[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'social_media_hours_xf[0][0]'\n",
      "                                                                    , 'netflix_hours_xf[0][0]',   \n",
      "                                                                     'attendance_percentage_xf[0][\n",
      "                                                                    0]',                          \n",
      "                                                                     'sleep_hours_xf[0][0]',      \n",
      "                                                                     'mental_health_rating_xf[0][0\n",
      "                                                                    ]',                           \n",
      "                                                                     'exercise_frequency_xf[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (None, 128)                  1152      ['concatenate_1[0][0]']       \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)         (None, 128)                  0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " dense_3 (Dense)             (None, 64)                   8256      ['dropout_1[0][0]']           \n",
      "                                                                                                  \n",
      " dense_4 (Dense)             (None, 1)                    65        ['dense_3[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 9473 (37.00 KB)\n",
      "Trainable params: 9473 (37.00 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/15\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 81.4226 - root_mean_squared_error: 9.0234 - val_loss: 429.1737 - val_root_mean_squared_error: 20.7165\n",
      "Epoch 2/15\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 36.0380 - root_mean_squared_error: 6.0032 - val_loss: 418.0866 - val_root_mean_squared_error: 20.4472\n",
      "Epoch 3/15\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 31.5761 - root_mean_squared_error: 5.6193 - val_loss: 403.9212 - val_root_mean_squared_error: 20.0978\n",
      "Epoch 4/15\n",
      "5000/5000 [==============================] - 14s 3ms/step - loss: 29.1963 - root_mean_squared_error: 5.4034 - val_loss: 434.3188 - val_root_mean_squared_error: 20.8403\n",
      "Epoch 5/15\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 27.4033 - root_mean_squared_error: 5.2348 - val_loss: 482.5679 - val_root_mean_squared_error: 21.9674\n",
      "Epoch 6/15\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 25.7377 - root_mean_squared_error: 5.0732 - val_loss: 474.4215 - val_root_mean_squared_error: 21.7812\n",
      "Epoch 7/15\n",
      "5000/5000 [==============================] - 13s 3ms/step - loss: 24.7605 - root_mean_squared_error: 4.9760 - val_loss: 457.0330 - val_root_mean_squared_error: 21.3783\n",
      "Epoch 8/15\n",
      "5000/5000 [==============================] - 12s 2ms/step - loss: 23.7288 - root_mean_squared_error: 4.8712 - val_loss: 462.0938 - val_root_mean_squared_error: 21.4964\n",
      "Epoch 9/15\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 22.8253 - root_mean_squared_error: 4.7776 - val_loss: 467.0952 - val_root_mean_squared_error: 21.6124\n",
      "Epoch 10/15\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 22.3128 - root_mean_squared_error: 4.7236 - val_loss: 441.6079 - val_root_mean_squared_error: 21.0145\n",
      "Epoch 11/15\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 21.7711 - root_mean_squared_error: 4.6660 - val_loss: 466.2274 - val_root_mean_squared_error: 21.5923\n",
      "Epoch 12/15\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 21.2701 - root_mean_squared_error: 4.6120 - val_loss: 449.6372 - val_root_mean_squared_error: 21.2046\n",
      "Epoch 13/15\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 20.8684 - root_mean_squared_error: 4.5682 - val_loss: 471.0146 - val_root_mean_squared_error: 21.7029\n",
      "Epoch 14/15\n",
      "5000/5000 [==============================] - 10s 2ms/step - loss: 20.3004 - root_mean_squared_error: 4.5056 - val_loss: 442.8630 - val_root_mean_squared_error: 21.0443\n",
      "Epoch 15/15\n",
      "5000/5000 [==============================] - 9s 2ms/step - loss: 20.0039 - root_mean_squared_error: 4.4726 - val_loss: 432.5353 - val_root_mean_squared_error: 20.7975\n",
      "INFO:tensorflow:Assets written to: raffihakim-pipeline/Trainer/model/7/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: raffihakim-pipeline/Trainer/model/7/Format-Serving/assets\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 7/9 Trainer Selesai\n"
     ]
    }
   ],
   "source": [
    "# 7. Trainer\n",
    "trainer = Trainer(\n",
    "    module_file=TRAINER_MODULE_FILE,\n",
    "    examples=transform.outputs['transformed_examples'],\n",
    "    transform_graph=transform.outputs['transform_graph'],\n",
    "    schema=schema_gen.outputs['schema'],\n",
    "    hyperparameters=tuner.outputs['best_hyperparameters'],\n",
    "    train_args=trainer_pb2.TrainArgs(splits=['train'], num_steps=5000),\n",
    "    eval_args=trainer_pb2.EvalArgs(splits=['eval'], num_steps=1000)\n",
    ")\n",
    "context.run(trainer)\n",
    "print(\"âœ… 7/9 Trainer Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "89ed3536-635e-4592-a95a-0d79a6f96a1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… 8/9 Resolver Selesai\n"
     ]
    }
   ],
   "source": [
    "# 8. Resolver\n",
    "blessed_model_resolver = Resolver(\n",
    "    strategy_class=LatestBlessedModelStrategy,\n",
    "    model=Channel(type=Model),\n",
    "    model_blessing=Channel(type=ModelBlessing)\n",
    ").with_id('latest_blessed_model_resolver')\n",
    "context.run(blessed_model_resolver)\n",
    "print(\"âœ… 8/9 Resolver Selesai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "978ca43b-7a38-4a93-b582-bbd2d20ddee2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Evaluator.__init__() got an unexpected keyword argument 'transform_graph'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_10085/243602702.py\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mmetrics_specs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetricsSpec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtfma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMetricConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclass_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'RootMeanSquaredError'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m )\n\u001b[0;32m----> 7\u001b[0;31m evaluator = Evaluator(\n\u001b[0m\u001b[1;32m      8\u001b[0m     \u001b[0mexamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexample_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'examples'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Evaluator.__init__() got an unexpected keyword argument 'transform_graph'"
     ]
    }
   ],
   "source": [
    "# 9. Evaluator & Pusher\n",
    "eval_config = tfma.EvalConfig(\n",
    "    model_specs=[tfma.ModelSpec(label_key='exam_score_xf')],\n",
    "    slicing_specs=[tfma.SlicingSpec()],\n",
    "    metrics_specs=[tfma.MetricsSpec(metrics=[tfma.MetricConfig(class_name='RootMeanSquaredError')])]\n",
    ")\n",
    "evaluator = Evaluator(\n",
    "    examples=example_gen.outputs['examples'],\n",
    "    model=trainer.outputs['model'],\n",
    "    baseline_model=blessed_model_resolver.outputs.get('model'),\n",
    "    eval_config=eval_config,\n",
    "    transform_graph=transform.outputs['transform_graph']\n",
    ")\n",
    "context.run(evaluator, enable_cache=False)\n",
    "print(\"âœ… 9/9 Evaluator Selesai\")\n",
    "\n",
    "pusher = Pusher(\n",
    "    model=trainer.outputs['model'],\n",
    "    model_blessing=evaluator.outputs['blessing'],\n",
    "    push_destination=pusher_pb2.PushDestination(filesystem=pusher_pb2.PushDestination.Filesystem(base_directory=SERVING_MODEL_DIR))\n",
    ")\n",
    "context.run(pusher)\n",
    "print(\"ðŸš€ðŸš€ðŸš€ Pusher Selesai, Pipeline Lengkap! ðŸš€ðŸš€ðŸš€\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b36ffb57-7836-4616-bd12-4d4a1b1b7b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-07-08 14:51:37.624448: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-07-08 14:51:37.634380: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-08 14:51:37.737553: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-07-08 14:51:37.737707: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-07-08 14:51:37.750224: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-07-08 14:51:37.791148: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-07-08 14:51:37.791988: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-07-08 14:51:56.959232: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-07-08 14:53:03.986498: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:887] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2025-07-08 14:53:04.005999: W tensorflow/core/common_runtime/gpu/gpu_device.cc:2256] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n",
      "usage: saved_model_cli show [-h] [--helpfull]\n",
      "saved_model_cli show: error: flag --dir=None: Flag --dir must have a value other than None.\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742b9d76-cd41-4512-8b80-00b0cb40aab2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (MLOps Project)",
   "language": "python",
   "name": "mlops"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
